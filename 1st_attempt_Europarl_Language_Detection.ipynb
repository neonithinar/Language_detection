{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " 1st attempt: Europarl Language Detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neonithinar/Language_detection/blob/main/1st_attempt_Europarl_Language_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjOnjfPUza3l"
      },
      "source": [
        "# Language identification using N-grams\n",
        "We will be using trigrams to identify the language\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xm_M67BXy_vk"
      },
      "source": [
        "# Common Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "import time\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.utils import np_utils\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFA2lralDdYQ"
      },
      "source": [
        "Mount the google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVOdINfGCYL4",
        "outputId": "b7136e34-d4de-4535-bc0f-42a69df3688d"
      },
      "source": [
        "! pwd\n",
        "! mkdir europarl\n",
        "! cd europarl\n",
        "! pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlLppdn7cTd0",
        "outputId": "95dc5845-a795-4a81-b262-d8081886d002"
      },
      "source": [
        "#! wget https://drive.google.com/file/d/1dKnhm9bdUF7KDkvp_IpyPSguXaBBIJFa/view?usp=sharing"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-04 05:48:26--  https://docs.google.com/u/0/nonceSigner?nonce=6op4hf6pumiqe\n",
            "Resolving docs.google.com (docs.google.com)... 74.125.142.138, 74.125.142.100, 74.125.142.101, ...\n",
            "Connecting to docs.google.com (docs.google.com)|74.125.142.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://docs.google.com/nonceSigner?nonce=6op4hf6pumiqe [following]\n",
            "--2021-02-04 05:48:26--  https://docs.google.com/nonceSigner?nonce=6op4hf6pumiqe\n",
            "Reusing existing connection to docs.google.com:443.\n",
            "HTTP request sent, awaiting response... 400 Bad Request\n",
            "2021-02-04 05:48:26 ERROR 400: Bad Request.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uk_B9SincTa6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yf6-omgQAq-A"
      },
      "source": [
        "lang = ['bulg', 'dani','germ', 'gree', 'span', 'esto', 'finn', 'fren', 'hung', 'ital', 'lith', 'latv', 'dutc', 'poli', 'port', 'roma', 'slvk', 'slve', 'swed']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        },
        "id": "SiZ_yVoN8MLo",
        "outputId": "ab7c81bb-ae27-4b89-9f97-0a311d937ed9"
      },
      "source": [
        "df = pd.DataFrame({'languages': ['bulg', 'dani','germ', 'gree', 'span', 'esto', 'finn', 'fren', 'hung', 'ital', 'lith', 'latv', 'dutc', 'poli', 'port', 'roma', 'slvk', 'slve', 'swed'], \n",
        "                   'paths':['/content/drive/MyDrive/Europarl/bg-en.tgz', '/content/drive/MyDrive/Europarl/da-en.tgz', '/content/drive/MyDrive/Europarl/de-en.tgz', '/content/drive/MyDrive/Europarl/el-en.tgz', '/content/drive/MyDrive/Europarl/es-en.tgz', '/content/drive/MyDrive/Europarl/et-en.tgz', '/content/drive/MyDrive/Europarl/fi-en.tgz', '/content/drive/MyDrive/Europarl/fr-en.tgz','/content/drive/MyDrive/Europarl/hu-en.tgz', '/content/drive/MyDrive/Europarl/it-en.tgz', '/content/drive/MyDrive/Europarl/lt-en.tgz', '/content/drive/MyDrive/Europarl/lv-en.tgz','/content/drive/MyDrive/Europarl/nl-en.tgz', '/content/drive/MyDrive/Europarl/pl-en.tgz', '/content/drive/MyDrive/Europarl/pt-en.tgz', '/content/drive/MyDrive/Europarl/ro-en.tgz', '/content/drive/MyDrive/Europarl/sk-en.tgz', '/content/drive/MyDrive/Europarl/sl-en.tgz', '/content/drive/MyDrive/Europarl/sv-en.tgz']})\n",
        "df\n",
        "                            "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>languages</th>\n",
              "      <th>paths</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bulg</td>\n",
              "      <td>/content/drive/MyDrive/Europarl/bg-en.tgz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>dani</td>\n",
              "      <td>/content/drive/MyDrive/Europarl/da-en.tgz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>germ</td>\n",
              "      <td>/content/drive/MyDrive/Europarl/de-en.tgz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>gree</td>\n",
              "      <td>/content/drive/MyDrive/Europarl/el-en.tgz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>span</td>\n",
              "      <td>/content/drive/MyDrive/Europarl/es-en.tgz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>esto</td>\n",
              "      <td>/content/drive/MyDrive/Europarl/et-en.tgz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>finn</td>\n",
              "      <td>/content/drive/MyDrive/Europarl/fi-en.tgz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>fren</td>\n",
              "      <td>/content/drive/MyDrive/Europarl/fr-en.tgz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>hung</td>\n",
              "      <td>/content/drive/MyDrive/Europarl/hu-en.tgz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>ital</td>\n",
              "      <td>/content/drive/MyDrive/Europarl/it-en.tgz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>lith</td>\n",
              "      <td>/content/drive/MyDrive/Europarl/lt-en.tgz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>latv</td>\n",
              "      <td>/content/drive/MyDrive/Europarl/lv-en.tgz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>dutc</td>\n",
              "      <td>/content/drive/MyDrive/Europarl/nl-en.tgz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>poli</td>\n",
              "      <td>/content/drive/MyDrive/Europarl/pl-en.tgz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>port</td>\n",
              "      <td>/content/drive/MyDrive/Europarl/pt-en.tgz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>roma</td>\n",
              "      <td>/content/drive/MyDrive/Europarl/ro-en.tgz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>slvk</td>\n",
              "      <td>/content/drive/MyDrive/Europarl/sk-en.tgz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>slve</td>\n",
              "      <td>/content/drive/MyDrive/Europarl/sl-en.tgz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>swed</td>\n",
              "      <td>/content/drive/MyDrive/Europarl/sv-en.tgz</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   languages                                      paths\n",
              "0       bulg  /content/drive/MyDrive/Europarl/bg-en.tgz\n",
              "1       dani  /content/drive/MyDrive/Europarl/da-en.tgz\n",
              "2       germ  /content/drive/MyDrive/Europarl/de-en.tgz\n",
              "3       gree  /content/drive/MyDrive/Europarl/el-en.tgz\n",
              "4       span  /content/drive/MyDrive/Europarl/es-en.tgz\n",
              "5       esto  /content/drive/MyDrive/Europarl/et-en.tgz\n",
              "6       finn  /content/drive/MyDrive/Europarl/fi-en.tgz\n",
              "7       fren  /content/drive/MyDrive/Europarl/fr-en.tgz\n",
              "8       hung  /content/drive/MyDrive/Europarl/hu-en.tgz\n",
              "9       ital  /content/drive/MyDrive/Europarl/it-en.tgz\n",
              "10      lith  /content/drive/MyDrive/Europarl/lt-en.tgz\n",
              "11      latv  /content/drive/MyDrive/Europarl/lv-en.tgz\n",
              "12      dutc  /content/drive/MyDrive/Europarl/nl-en.tgz\n",
              "13      poli  /content/drive/MyDrive/Europarl/pl-en.tgz\n",
              "14      port  /content/drive/MyDrive/Europarl/pt-en.tgz\n",
              "15      roma  /content/drive/MyDrive/Europarl/ro-en.tgz\n",
              "16      slvk  /content/drive/MyDrive/Europarl/sk-en.tgz\n",
              "17      slve  /content/drive/MyDrive/Europarl/sl-en.tgz\n",
              "18      swed  /content/drive/MyDrive/Europarl/sv-en.tgz"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Zz7M5tRc7WlC",
        "outputId": "83319c74-efb6-438c-d326-5e6854a53bd6"
      },
      "source": [
        "df.loc[3, \"paths\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/Europarl/el-en.tgz'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDVV4w-uzQwv"
      },
      "source": [
        "import tarfile\n",
        "import os\n",
        "\n",
        "def extract_files(tgz_path):\n",
        "  path  = os.path.join(tgz_path)\n",
        "  my_tar = tarfile.open(path)\n",
        "  my_tar.extractall('./europarl') # specify which folder to extract to\n",
        "  my_tar.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xHOO8JW5sOz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c0231f0-cfef-40dd-e793-f9df5b91d70b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYaunPPOzQz0"
      },
      "source": [
        "# Extract the files into the europarl dataset\n",
        "for i in range(19):\n",
        "  extract_files(df.loc[i, \"paths\"])\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Y9_7KlHEGao"
      },
      "source": [
        "Trying out the text extraction with one of the data files in europarl folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iq8yOpiOzQ2V"
      },
      "source": [
        "# load doc into memory\n",
        "def load_doc(filename):\n",
        "\t# open the file as read only\n",
        "\tfile = open(filename, mode='rt', encoding='utf-8')\n",
        "\t# read all text\n",
        "\ttext = file.read()\n",
        "\t# close the file\n",
        "\tfile.close()\n",
        "\treturn text\n",
        " \n",
        "# split a loaded document into sentences\n",
        "def to_sentences(doc):\n",
        "\treturn doc.strip().split('\\n')\n",
        " \n",
        "# shortest and longest sentence lengths\n",
        "def sentence_lengths(sentences):\n",
        "\tlengths = [len(s.split()) for s in sentences]\n",
        "\treturn min(lengths), max(lengths)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwxeFRxCAYml"
      },
      "source": [
        "def clean_trigrams(filename):\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_eW6gHdzQ5M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3fac967-9721-4dca-ce97-975a1e06b85d"
      },
      "source": [
        " \n",
        "# load English data\n",
        "filename = '/content/europarl/europarl-v7.fr-en.en'\n",
        "doc = load_doc(filename)\n",
        "sentences = to_sentences(doc)\n",
        "minlen, maxlen = sentence_lengths(sentences)\n",
        "print('English data: sentences=%d, min=%d, max=%d' % (len(sentences), minlen, maxlen))\n",
        "#print(sentences)\n",
        "\n",
        " \n",
        "# # load French data\n",
        "# filename = 'europarl-v7.fr-en.fr'\n",
        "# doc = load_doc(filename)\n",
        "# sentences = to_sentences(doc)\n",
        "# minlen, maxlen = sentence_lengths(sentences)\n",
        "# print('French data: sentences=%d, min=%d, max=%d' % (len(sentences), minlen, maxlen))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLqJD22jF8PK"
      },
      "source": [
        "sentences = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ncq1xehlFzh6",
        "outputId": "99712e09-4845-49f6-ecac-535601c295e8"
      },
      "source": [
        "# load French data\n",
        "filename = '/content/europarl/europarl-v7.fr-en.fr'\n",
        "doc = load_doc(filename)\n",
        "sentences = to_sentences(doc)\n",
        "minlen, maxlen = sentence_lengths(sentences)\n",
        "print('French data: sentences=%d, min=%d, max=%d' % (len(sentences), minlen, maxlen))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "French data: sentences=2007723, min=0, max=693\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7e7egbHzQ_D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c8134ed-af98-4d58-af2f-62fb1f5cc949"
      },
      "source": [
        "# check the sentences\n",
        "for i in range(10):\n",
        "  print(sentences[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reprise de la session\n",
            "Je déclare reprise la session du Parlement européen qui avait été interrompue le vendredi 17 décembre dernier et je vous renouvelle tous mes vux en espérant que vous avez passé de bonnes vacances.\n",
            "Comme vous avez pu le constater, le grand \"bogue de l'an 2000\" ne s'est pas produit. En revanche, les citoyens d'un certain nombre de nos pays ont été victimes de catastrophes naturelles qui ont vraiment été terribles.\n",
            "Vous avez souhaité un débat à ce sujet dans les prochains jours, au cours de cette période de session.\n",
            "En attendant, je souhaiterais, comme un certain nombre de collègues me l'ont demandé, que nous observions une minute de silence pour toutes les victimes, des tempêtes notamment, dans les différents pays de l'Union européenne qui ont été touchés.\n",
            "Je vous invite à vous lever pour cette minute de silence.\n",
            "(Le Parlement, debout, observe une minute de silence)\n",
            "Madame la Présidente, c'est une motion de procédure.\n",
            "Vous avez probablement appris par la presse et par la télévision que plusieurs attentats à la bombe et crimes ont été perpétrés au Sri Lanka.\n",
            "L'une des personnes qui vient d'être assassinée au Sri Lanka est M. Kumar Ponnambalam, qui avait rendu visite au Parlement européen il y a quelques mois à peine.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1B1KdJhMCSm8"
      },
      "source": [
        "# Clean the text\n",
        "\n",
        "\n",
        "\n",
        "tokenize the set by white space\n",
        "\n",
        "Normalise the characters to lower case\n",
        "\n",
        "Remove punctuation from each word\n",
        "\n",
        "Remove non-printable characters\n",
        "\n",
        "convert french characters to latin characters\n",
        "\n",
        "Remove words that contain non-alphabetic characters\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtFXz62XCSED"
      },
      "source": [
        "import string\n",
        "import re\n",
        "from pickle import dump\n",
        "from unicodedata import normalize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4O3SbBzzRBn"
      },
      "source": [
        "def clean_text(lines):\n",
        "\tcleaned = list()\n",
        "\t# prepare regex for char filtering\n",
        "\tre_print = re.compile('[^%s]' % re.escape(string.printable))\n",
        "\t# prepare translation table for removing punctuation\n",
        "\ttable = str.maketrans('', '', string.punctuation)\n",
        "\tfor line in lines:\n",
        "\t\t# normalize unicode characters\n",
        "\t\t# line = normalize('NFD', line).encode('ascii', 'ignore')\n",
        "\t\t# line = line.decode('UTF-8')\n",
        "\t\t# tokenize on white space\n",
        "\t\tline = line.split()\n",
        "\t\t# convert to lower case\n",
        "\t\tline = [word.lower() for word in line]\n",
        "\t\t# remove punctuation from each token\n",
        "\t\tline = [word.translate(table) for word in line]\n",
        "\t\t# remove non-printable chars form each token\n",
        "\t\tline = [re_print.sub('', w) for w in line]\n",
        "\t\t# remove tokens with numbers in them\n",
        "\t\tline = [word for word in line if word.isalpha()]\n",
        "\t\t# store as string\n",
        "\t\tcleaned.append(' '.join(line))\n",
        "\treturn cleaned"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMZacs1vH8bj"
      },
      "source": [
        "We will be saving the list of cleaned sentences to a file, that will later be compiled to a dataframe in another notebook. The notebook may not handle such large amount of data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeWFWHijzREQ"
      },
      "source": [
        "# save a list of clean sentences to file\n",
        "def save_clean_sentences(sentences, filename):\n",
        "\tdump(sentences, open(filename, 'wb'))\n",
        "\tprint('Saved: %s' % filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLz9kcC0zRGq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af6f2acf-84ae-4205-bdff-e3f9b1ccb002"
      },
      "source": [
        "sentences = clean_text(sentences)\n",
        "print(len(sentences))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2007723\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDL0y03OzRJt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1ddd420-4e3b-4425-b905-46fae3aa9b11"
      },
      "source": [
        "# check the sentences\n",
        "for i in range(10):\n",
        "  print(sentences[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reprise de la session\n",
            "je declare reprise la session du parlement europeen qui avait ete interrompue le vendredi decembre dernier et je vous renouvelle tous mes vux en esperant que vous avez passe de bonnes vacances\n",
            "comme vous avez pu le constater le grand bogue de lan ne sest pas produit en revanche les citoyens dun certain nombre de nos pays ont ete victimes de catastrophes naturelles qui ont vraiment ete terribles\n",
            "vous avez souhaite un debat a ce sujet dans les prochains jours au cours de cette periode de session\n",
            "en attendant je souhaiterais comme un certain nombre de collegues me lont demande que nous observions une minute de silence pour toutes les victimes des tempetes notamment dans les differents pays de lunion europeenne qui ont ete touches\n",
            "je vous invite a vous lever pour cette minute de silence\n",
            "le parlement debout observe une minute de silence\n",
            "madame la presidente cest une motion de procedure\n",
            "vous avez probablement appris par la presse et par la television que plusieurs attentats a la bombe et crimes ont ete perpetres au sri lanka\n",
            "lune des personnes qui vient detre assassinee au sri lanka est m kumar ponnambalam qui avait rendu visite au parlement europeen il y a quelques mois a peine\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62qX8hV-zRM2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29fb43c9-e91c-4dcf-eb75-3e9e918d1453"
      },
      "source": [
        "# save_clean_sentences(sentences, 'french.pkl')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved: french.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yOYvzI1Lue5"
      },
      "source": [
        "**Manually deleting all the english files except one**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oS-isXhBzRSt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68dafccd-9d2b-4919-8416-c74ede94e5f8"
      },
      "source": [
        "len(sentences)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2007723"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTBadJJHUv-J"
      },
      "source": [
        "Hmmm, I am confused..\n",
        "should i split the data now or should I do so afterwards? after reducing the vocabulary?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYGGlYO2zRVV"
      },
      "source": [
        "reduced_vocab = []\n",
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9rWvPUWzRYJ"
      },
      "source": [
        " \n",
        "# create a frequency table for all words\n",
        "def to_vocab(lines):\n",
        "\tvocab = Counter()\n",
        "\tfor line in lines:\n",
        "\t\ttokens = line.split()\n",
        "\t\tvocab.update(tokens)\n",
        "\treturn vocab\n",
        " \n",
        "# remove all words with a frequency below a threshold\n",
        "def trim_vocab(vocab, min_occurance):\n",
        "\ttokens = [k for k,c in vocab.items() if c >= min_occurance]\n",
        "\treturn set(tokens)\n",
        " \n",
        "# mark all OOV with \"unk\" for all lines\n",
        "def update_dataset(lines, vocab):\n",
        "\tnew_lines = list()\n",
        "\tfor line in lines:\n",
        "\t\tnew_tokens = list()\n",
        "\t\tfor token in line.split():\n",
        "\t\t\tif token in vocab:\n",
        "\t\t\t\tnew_tokens.append(token)\n",
        "\t\t\telse:\n",
        "\t\t\t\tnew_tokens.append('unk')\n",
        "\t\tnew_line = ' '.join(new_tokens)\n",
        "\t\tnew_lines.append(new_line)\n",
        "\treturn new_lines"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fdln_tDZzRaz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d02e437-1533-4905-b8cb-d5d2ad219d0b"
      },
      "source": [
        "reduced_vocab = to_vocab(sentences)\n",
        "print(\"vocabulary list:\", len(reduced_vocab))\n",
        "reduced_vocab = trim_vocab(reduced_vocab, 5)\n",
        "print(\"Reduced vocab:\", len(reduced_vocab))\n",
        "new_sentences = update_dataset(sentences, reduced_vocab)\n",
        "print(\"length of new sentences after reducing vocab:\", len(new_sentences))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocabulary list: 141642\n",
            "Reduced vocab: 58800\n",
            "length of new sentences after reducing vocab: 2007723\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWI2XX6CeTi4"
      },
      "source": [
        "Okay... That clears it. the length of the sentences will remain same, so train split may not be so problematic\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAjObKy4zRds",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4398292d-2a6a-459d-d930-97cab96a5301"
      },
      "source": [
        "# check the sentences\n",
        "for i in range(10):\n",
        "  print(new_sentences[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reprise de la session\n",
            "je declare reprise la session du parlement europeen qui avait ete interrompue le vendredi decembre dernier et je vous renouvelle tous mes vux en esperant que vous avez passe de bonnes vacances\n",
            "comme vous avez pu le constater le grand bogue de lan ne sest pas produit en revanche les citoyens dun certain nombre de nos pays ont ete victimes de catastrophes naturelles qui ont vraiment ete terribles\n",
            "vous avez souhaite un debat a ce sujet dans les prochains jours au cours de cette periode de session\n",
            "en attendant je souhaiterais comme un certain nombre de collegues me lont demande que nous observions une minute de silence pour toutes les victimes des tempetes notamment dans les differents pays de lunion europeenne qui ont ete touches\n",
            "je vous invite a vous lever pour cette minute de silence\n",
            "le parlement debout observe une minute de silence\n",
            "madame la presidente cest une motion de procedure\n",
            "vous avez probablement appris par la presse et par la television que plusieurs attentats a la bombe et crimes ont ete perpetres au sri lanka\n",
            "lune des personnes qui vient detre assassinee au sri lanka est m unk unk qui avait rendu visite au parlement europeen il y a quelques mois a peine\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nONjI6zqfKDb"
      },
      "source": [
        "Wait a min.. does converting to the latin counter part create some kind of translation problems? Darn... Should have omitted the thing\n",
        "\n",
        "Now that is done with, we need to run the entire thing from the begining. good thing that connection was reset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUXK52XlgbFp"
      },
      "source": [
        "Now lets think about the dataframe that will hold the entire trasformation columns and sentences. I think, Dataset can be created from within the previous function itself. Looping through the filenames that was extracted from the tgz files\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpsypvtrzRPn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c4608a7-b8f4-4639-e03f-0afad97ff4c0"
      },
      "source": [
        "import os\n",
        "for dir_path, dir_names, filenames in os.walk(\"/content/europarl\"):\n",
        "  for i in filenames:\n",
        "    # to do map the filenames to the lang identifier list\n",
        "    \n",
        "\n",
        "\n",
        "    print(\"Processing\")\n",
        "    file_path = dir_path + i \n",
        "    print(file_path)\n",
        "    sentences = []\n",
        "    doc = load_doc(filename)\n",
        "    sentences = to_sentences(doc)\n",
        "    print(\"length of sentences:\", len(sentences))\n",
        "    sentences = clean_text(sentences)\n",
        "    print(\"length of sentences after cleaning:\", len(sentences))\n",
        "    # save_clean_sentences(sentences, i+'.pkl')\n",
        "    # print(\"saved !\", i+'.pkl')\n",
        "    reduced_vocab = to_vocab(sentences)\n",
        "    print(\"vocabulary list:\", len(reduced_vocab))\n",
        "    reduced_vocab = trim_vocab(reduced_vocab, 5)\n",
        "    print(\"Reduced vocab:\", len(reduced_vocab))\n",
        "    new_sentences = update_dataset(sentences, reduced_vocab)\n",
        "    print(\"length of new sentences after reducing vocab:\", len(new_sentences))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing\n",
            "/content/europarleuroparl-v7.lv-en.lv\n",
            "length of sentences: 2007723\n",
            "length of sentences after cleaning: 2007723\n",
            "Saved: europarl-v7.lv-en.lv.pkl\n",
            "saved ! europarl-v7.lv-en.lv.pkl\n",
            "Processing\n",
            "/content/europarleuroparl-v7.sk-en.sk\n",
            "length of sentences: 2007723\n",
            "length of sentences after cleaning: 2007723\n",
            "Saved: europarl-v7.sk-en.sk.pkl\n",
            "saved ! europarl-v7.sk-en.sk.pkl\n",
            "Processing\n",
            "/content/europarleuroparl-v7.de-en.de\n",
            "length of sentences: 2007723\n",
            "length of sentences after cleaning: 2007723\n",
            "Saved: europarl-v7.de-en.de.pkl\n",
            "saved ! europarl-v7.de-en.de.pkl\n",
            "Processing\n",
            "/content/europarleuroparl-v7.et-en.et\n",
            "length of sentences: 2007723\n",
            "length of sentences after cleaning: 2007723\n",
            "Saved: europarl-v7.et-en.et.pkl\n",
            "saved ! europarl-v7.et-en.et.pkl\n",
            "Processing\n",
            "/content/europarleuroparl-v7.el-en.el\n",
            "length of sentences: 2007723\n",
            "length of sentences after cleaning: 2007723\n",
            "Saved: europarl-v7.el-en.el.pkl\n",
            "saved ! europarl-v7.el-en.el.pkl\n",
            "Processing\n",
            "/content/europarleuroparl-v7.lt-en.lt\n",
            "length of sentences: 2007723\n",
            "length of sentences after cleaning: 2007723\n",
            "Saved: europarl-v7.lt-en.lt.pkl\n",
            "saved ! europarl-v7.lt-en.lt.pkl\n",
            "Processing\n",
            "/content/europarleuroparl-v7.da-en.da\n",
            "length of sentences: 2007723\n",
            "length of sentences after cleaning: 2007723\n",
            "Saved: europarl-v7.da-en.da.pkl\n",
            "saved ! europarl-v7.da-en.da.pkl\n",
            "Processing\n",
            "/content/europarleuroparl-v7.it-en.it\n",
            "length of sentences: 2007723\n",
            "length of sentences after cleaning: 2007723\n",
            "Saved: europarl-v7.it-en.it.pkl\n",
            "saved ! europarl-v7.it-en.it.pkl\n",
            "Processing\n",
            "/content/europarleuroparl-v7.es-en.es\n",
            "length of sentences: 2007723\n",
            "length of sentences after cleaning: 2007723\n",
            "Saved: europarl-v7.es-en.es.pkl\n",
            "saved ! europarl-v7.es-en.es.pkl\n",
            "Processing\n",
            "/content/europarleuroparl-v7.hu-en.hu\n",
            "length of sentences: 2007723\n",
            "length of sentences after cleaning: 2007723\n",
            "Saved: europarl-v7.hu-en.hu.pkl\n",
            "saved ! europarl-v7.hu-en.hu.pkl\n",
            "Processing\n",
            "/content/europarleuroparl-v7.fi-en.fi\n",
            "length of sentences: 2007723\n",
            "length of sentences after cleaning: 2007723\n",
            "Saved: europarl-v7.fi-en.fi.pkl\n",
            "saved ! europarl-v7.fi-en.fi.pkl\n",
            "Processing\n",
            "/content/europarleuroparl-v7.bg-en.en\n",
            "length of sentences: 2007723\n",
            "length of sentences after cleaning: 2007723\n",
            "Saved: europarl-v7.bg-en.en.pkl\n",
            "saved ! europarl-v7.bg-en.en.pkl\n",
            "Processing\n",
            "/content/europarleuroparl-v7.sl-en.sl\n",
            "length of sentences: 2007723\n",
            "length of sentences after cleaning: 2007723\n",
            "Saved: europarl-v7.sl-en.sl.pkl\n",
            "saved ! europarl-v7.sl-en.sl.pkl\n",
            "Processing\n",
            "/content/europarleuroparl-v7.pl-en.pl\n",
            "length of sentences: 2007723\n",
            "length of sentences after cleaning: 2007723\n",
            "Saved: europarl-v7.pl-en.pl.pkl\n",
            "saved ! europarl-v7.pl-en.pl.pkl\n",
            "Processing\n",
            "/content/europarleuroparl-v7.ro-en.ro\n",
            "length of sentences: 2007723\n",
            "length of sentences after cleaning: 2007723\n",
            "Saved: europarl-v7.ro-en.ro.pkl\n",
            "saved ! europarl-v7.ro-en.ro.pkl\n",
            "Processing\n",
            "/content/europarleuroparl-v7.bg-en.bg\n",
            "length of sentences: 2007723\n",
            "length of sentences after cleaning: 2007723\n",
            "Saved: europarl-v7.bg-en.bg.pkl\n",
            "saved ! europarl-v7.bg-en.bg.pkl\n",
            "Processing\n",
            "/content/europarleuroparl-v7.pt-en.pt\n",
            "length of sentences: 2007723\n",
            "length of sentences after cleaning: 2007723\n",
            "Saved: europarl-v7.pt-en.pt.pkl\n",
            "saved ! europarl-v7.pt-en.pt.pkl\n",
            "Processing\n",
            "/content/europarleuroparl-v7.sv-en.sv\n",
            "length of sentences: 2007723\n",
            "length of sentences after cleaning: 2007723\n",
            "Saved: europarl-v7.sv-en.sv.pkl\n",
            "saved ! europarl-v7.sv-en.sv.pkl\n",
            "Processing\n",
            "/content/europarleuroparl-v7.nl-en.nl\n",
            "length of sentences: 2007723\n",
            "length of sentences after cleaning: 2007723\n",
            "Saved: europarl-v7.nl-en.nl.pkl\n",
            "saved ! europarl-v7.nl-en.nl.pkl\n",
            "Processing\n",
            "/content/europarleuroparl-v7.fr-en.fr\n",
            "length of sentences: 2007723\n",
            "length of sentences after cleaning: 2007723\n",
            "Saved: europarl-v7.fr-en.fr.pkl\n",
            "saved ! europarl-v7.fr-en.fr.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sChEjpkHzRgQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qsu8xpr_zRjT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50KIolhIzRmF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRF8oGCCzRpG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWcJ8Qb7zRr4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sS6Utq5OzRvO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvrHw-q4zRya"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgzvhG1KzR11"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ia0gTxYJzR4q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJVJ0nbTzR6u"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adk66dVgzR9j"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}